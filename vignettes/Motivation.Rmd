---
title: "Motivation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Motivation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

> "A dataset is an identifiable collection of data available for access or download in one or more formats." ISO/IEC 20546

```{r setup}
library(dataset)
```

The `dataset` package aims to enhance the semantic richness of R datasets, particularly tabular data derived from the `data.frame` class. Its goal is to create "tidy" datasets from the outset, promoting reusability and interoperability. Through several iterations, it became clear that this goal is intrinsically linked to the dataset's intended purpose. Consequently, `dataset` has evolved from a single package into a family of related packages.

## Problem statement

```{r example-ambiguity}
data.frame(
  geo = c("LI", "SM"),
  CPI = c("0.8", "0.9"),
  GNI = c("8976", "9672")
)
```

This dataset is tidy. But it certainly could be improved!

-   `geo`: you may figure out that geo means something to do with geography (maybe countries, "LI" standing for Lichtenstein and "SM" for San Marino), but even that, who knows? If you add Greece, should use use "EL" like Eurostat or "GR" like the World Bank?

-   `CPI` can stand for "consumer price index" or "corruption perceptions index". Or anything else!

-   `GNI` can stand for "Gross National Income" and "Global Nutrition Index", often mentioned in the same context. If there are numbers, do they mean a physical quantity or a currency? Is the currency dollars or euros?

```{r smallcountrydataset}
options(sciphen = 4)
small_country_dataset <- dataset_df(
  country_name = defined(
    c("AD", "LI"),
    definition = "http://data.europa.eu/bna/c_6c2bb82d",
    namespace = "https://www.geonames.org/countries/$1/"
  ),
  gdp = defined(
    c(3897, 7365),
    label = "Gross Domestic Product",
    unit = "million dollars",
    definition = "http://data.europa.eu/83i/aa/GDP"
  ),
  population = defined(
    c(77543, 40015),
    label = "Population",
    definition = "http://data.europa.eu/bna/c_f2b50efd"
  ),
  dataset_bibentry = dublincore(
    creator = person(given = "Jane", family = "Doe"),
    title = "Small Country Dataset",
    publisher = "Reprex"
  )
)
```

```{r percapita}
small_country_dataset$gdp_capita <- defined(
  small_country_dataset$gdp * 1e6 / small_country_dataset$population,
  unit = "dollar",
  label = "GDP Per Capita"
)
```

Interoperability and future (re)usability depends on the amount and quality of the metadata that was generated, recorded, and released together with the data. The `dataset` package aims to collect such metadata and record them in the least possible intrusive way.

-   [x] `Descriptive metadata`, about the dataset as a whole, to improve findability and accessibility; in this regard, follow the DCTERMS and DataCite standards.
-   [x] Metadata about the `structural elements` within the dataset; better definitions of the row identifier (instead of local, encourage global IDs), and utilise global definitions for variables. Include unit of measure to disallow semantically incorrect joins.
-   [x] Add `provenance metadata`, so the next user can understand where each data elements came, and what happened with them.

## Limits on reusability

Let's take a look at the limitations of two, tidy datasets from an interoperability and reusability point of view:

```{r gdpexmampel}
library(tibble)
library(dplyr)
library(tidyr)

# Dataset D (GDP in billions of USD)
D <- tibble(
  year = c(2020, 2020, 2021, 2021, 2022, 2022),
  geocode = c("USA", "CAN", "USA", "CAN", "USA", "CAN"),
  country_name = c("United States", "Canada", "United States", "Canada", "United States", "Canada"),
  GDP = c(21000, 2000, 22000, 2100, 23000, 2200) # GDP in billions of USD
)

# Dataset E (GDP in billions of EUR)
E <- tibble(
  year = c(2020, 2020, 2021, 2021, 2022, 2022),
  geocode = c("USA", "FRA", "USA", "FRA", "USA", "FRA"),
  country_name = c("United States", "France", "United States", "France", "United States", "France"),
  GDP = c(18000, 2500, 19000, 2600, 20000, 2700) # GDP in billions of EUR
)
```

The two datasets conform to the tidy data principles, and with the tidyverse functions, we can join them together into a single dataset. But should we?

```{r}
full_join(D, E)
```

Obviously, this join is valid syntactically, but seriously misleading, because some values are expressed in dollars, other in euros. This would be clear for a user who has access to the full creation code with the comments, but this is not always a realistic approach. The user may download the data from a CSV file and do not read R at all. The serialisation of the metadata (i.e., the currency use), and the data are detached, even in R. Not to mention other possible problems. The analyst may add another numeric variable called `CPI`, which may mean consumer price index or corruption perception index. There is no guarantee that a next user can use the dataset as intended.

While numerous R packages address metadata management in specific contexts, they often interact with datasets late in the process, primarily focusing on publication or external reuse, for example, after serialisation of CSV and publication on a website. The `dataset` family takes a different approach, embedding reusability from the moment a `data.frame` is created. This early intervention adds value and potentially amplifies the effectiveness of other metadata packages, but critically, also the reusability of R objects, too. We are building an extension of data.frames, tibbles, tsibbles and other tabular containers that retain the currency information; the full name of the CPI variable; and they prohibit a full join with semantically different variables of the same type.

Our work is informed by the European Interoperability Framework (EIF) and its principles of data governance. The EIF identifies four layers of interoperability: legal, organizational, semantic, and technical. While many R metadata packages concentrate on the technical aspects and incorporate legal metadata, the `dataset` family emphasizes the organizational and semantic layers, with leaving the technical elements of the interoperability to other packages like `frictionless`, `dataspice`, and `rdflib` (with the two last packages we plan a deep integration.)

Although we envision diverse future applications for these enhanced datasets, the current development focuses on a key distinction: whether the data will be reused in a tabular (relational database) or graph format. These two reuse scenarios have distinct metadata requirements, necessitating somewhat specialized approaches.

### Tidy data and graphs

While the semantic and descriptive metadata needs of graph and tabular data aren't entirely dissimilar (as demonstrated by Carl Boettinger's work showing how tabular data can be represented as RDF), the workflows for handling data originating from these different sources *do* vary significantly. Even though pivoting to a tidy, long-format dataset and serializing to RDF is a common approach for tabular data exchange, the initial source (graph, tabular database, etc.) influences data organization and subsequent semantic requirements. Therefore, the `dataset` package has two specialized extensions:

-   `datacube`: This planned downstream package prioritizes interoperability with the Statistical Data and Metadata Exchange (SDMX) standard. It enforces stricter adherence to the datacube model when working with `data.frame`s or `tibble`s. The target user is an analyst working with SDMX data sources (e.g., national statistical offices, Eurostat, World Bank). The goal is to enable seamless data transformation, extension, and mutation within R, followed by interoperable export back to an SDMX resource (e.g., the EU Open Data portal).

-   `wbdataset`: This already developing package focuses on interoperability with Wikidata and the Wikibase Data Model, the foundation of the world's largest open knowledge graph. The intended user is an analyst who downloads data from Wikidata (or a similar Wikibase instance), performs analysis in R, and then contributes the enriched dataset back to the knowledge graph.

-   `rdflib`: We will show that for native graph databases, the excellent `rdflib` package works excellent together with `dataset`.

In these cases, we assume users work with tabular data structures like `data.frame`s, `tibble`s, `tsibble`s, `DT` objects, etc., leveraging the broader R ecosystem. However, the two scenarios present distinct challenges. The SDMX-focused workflow (`datacube`) requires preserving more metadata than typical R usage and adhering to a higher standard of "tidiness" beyond conventional tidy data principles. The Wikidata/Wikibase scenario (`wbdataset`) involves conversion to and from semantic triples, reflecting the graph-based nature of the data.

## Our approach: utilise attributes

This document describes a new R package, `dataset`, designed to improve data interoperability for R's `data.frame` objects. The core concept is leveraging R's built-in `attributes()` function to store rich metadata. While `attributes()` allows attaching metadata to any R object, it's often underutilised. The `dataset` package promotes systematic use of attributes, ensuring crucial metadata isn't lost during data manipulation.

Specifically, `dataset` utilizes `person` and extended `bibentry` objects (from the `utils` package) within the attributes. This allows comprehensive descriptive metadata to be associated with the dataset. The package focuses on adhering to either [DCTERMS](https://www.dublincore.org/specifications/dublin-core/dcmi-terms/) (Dublin Core) or DataCite metadata standards, maintaining and even updating this metadata throughout the R workflow.

`person` objects, crucial for representing agents (creators, contributors, publishers) within the `bibentry`, enable structured metadata and support permanent identifiers like ORCIDs. While acknowledging limitations of `person` objects, their presence in the `utils` package ensures availability for all R users. (An initial attempt to use `RefManageR` objects for bibliographic information was abandoned due to conflicts with modern metadata standards.)

```{r d-enriched}
D_enriched <- dataset_df(
  year = c(2020, 2020, 2021, 2021, 2022, 2022),
  geocode = c("USA", "CAN", "USA", "CAN", "USA", "CAN"),
  country_name = c("United States", "Canada", "United States", "Canada", "United States", "Canada"),
  GDP = c(21000, 2000, 22000, 2100, 23000, 2200),
  dataset_bibentry = dataset::dublincore(
    title = "North American GDP Dataset",
    description = "Dataset containing GDP data for North American countries.",
    creator = person("Daniel", "Antal"), # Replace with the actual creator
    publisher = "Reprex",
    dataset_date = Sys.Date(),
    subject = "GDP"
  )
)

D_enriched
```

The enriched dataset gives us more information about the organisation of the dataset as a whole, but still suffers from a loose definition of its structural elements, i.e., the rows and the columns. We will come back to this in the following sections.

The `dataset` package provides functions with sensible defaults and structures compliant with international metadata standards. The `dublincore()` and `datacite()` functions create enhanced bibentry objects and offer many functions to change the elements of these objects (i.e., to change the publication year, the names of the contributors, etc.) These functions facilitate adding metadata about the dataset as a whole (i.e., the overall organization of the data, not individual rows or columns). It also establishes a foundation for adding metadata about the internal structure of the dataset, such as the meaning and intended use of rows and columns.

Currently, the `dataset` package's approach to row/column-level metadata differs depending on whether the data is intended for a "datacube" or "wbdataset" (likely referring to a specific data format or use case). This is because datasets reused in tabular or graph forms have distinct semantic requirements, which necessitate different function interfaces even if the underlying metadata needs are similar. Future development may address these differences more uniformly.

### Keep data and metadata together

The `dataset` package shares similar goals with the rOpenSci `dataspice` package, particularly concerning tabular data. `dataspice` focuses on making datasets more discoverable online by adding Schema.org metadata, a lightweight ontology used by web search engines. A key interoperability goal for `dataset` is to capture *all* the metadata that `dataspice` utilizes *throughout* the analytical workflow and store it directly within the R `data.frame`'s attributes.

While `dataspice` encourages users to provide this metadata separately in a CSV file (a convenient and simple approach), this method has two critical weaknesses:

1.  **User error:** Users may not complete the CSV file or might enter incorrect information.

2.  **Synchronization issues:** The released dataset and its metadata can become detached, lost, or fall out of sync due to later updates.

Knowledge graphs offer a more robust solution by updating data and metadata simultaneously, ensuring consistency and enforcing strict metadata definitions. The `dataset` package aims to promote continuous metadata collection and storage within the R object itself, saving it alongside the data. R's ability to store rich metadata in attributes makes saving in `.rda` or `.rds` files a compelling option, even if these formats aren't universally interoperable.

Inspired by knowledge graphs, `dataset` extends the use of attributes to include graph-like metadata, such as recording the dataset's provenance: who downloaded the original data, who performed manipulations, which R packages ("software agents") were used, and so on.

### From tidy to tidier

Tidy data principles, well-established among R users, promote data reusability through a simple structure: rows represent observations, and columns represent variables with meaningful names. This aligns with the 3NF normal form in relational databases and, as Carl Boettiger illustrates, can also represent graph entries in a 3-column long format (subject-predicate-object). However, two key limitations require going beyond standard tidy principles:

-   **Column name ambiguity:** Column names can be difficult to interpret and reuse over time. Richer semantic information about columns is essential for improved interoperability and reusability.

-   **Row name limitations:** Row names are local identifiers, hindering workflows involving joins and slices across multiple datasets.

While the `haven` and `labelled` packages in the tidyverse provide enhanced column labels (similar to SPSS and STATA), they are insufficient for complex workflows involving numerous datasets. `dataset` addresses these limitations in two ways:

-   **`defined()` class:** Inheriting from `labelled`, `defined()` adds a *definition* and a *namespace* to labels, enhancing their meaning and meeting the requirements for linked open data.

-   **Data provenance:** `dataset` records data provenance (who downloaded, manipulated, etc.) in the attributes, using a simplified version of the PROV model and PROV-O ontology. (Further development of this feature is planned for a separate package.)

The `defined()` class also allows extending tidyverse row IDs with a namespace or prefix, enabling conversion to globally unique identifiers (GUIDs), critical when working with data from many sources.

Beyond row and column identification, `dataset` addresses the question of *when* to define a new dataset, a challenge only partially answered in earlier versions and now delegated to the `datacube` package. This question hinges on the concept of a *datacube*, a structural enhancement of tidy data. Datacubes categorize variables into:

-   **Attributes:** Metadata constraints.

-   **Dimensions:** Variables suitable for summarizing or slicing data.

-   **Measures:** Values often requiring a unit of measure.

```{r}
library(tibble)
library(dplyr)

# Dataset D (GDP in billions of USD)
D <- tibble(
  year = c(2020, 2020, 2021, 2021, 2022, 2022),
  geocode = c("USA", "CAN", "USA", "CAN", "USA", "CAN"),
  country_name = c(
    "United States", "Canada", "United States",
    "Canada", "United States", "Canada"
  ),
  GDP = c(21000, 2000, 22000, 2100, 23000, 2200) # GDP in billions of USD
)

# Dataset E (GDP in billions of EUR)
E <- tibble(
  year = c(2020, 2020, 2021, 2021, 2022, 2022),
  geocode = c("USA", "FRA", "USA", "FRA", "USA", "FRA"),
  country_name = c("United States", "France", "United States", "France", "United States", "France"),
  GDP = c(18000, 2500, 19000, 2600, 20000, 2700) # GDP in billions of EUR
)

joined_data <- full_join(D, E)
joined_data
```

The `datacube` package emphasizes the distinction between these variable types. For example, joining datasets with shared row IDs and columns isn't meaningful without considering units of measure (e.g., euros vs. dollars). Dimensions determine when a new dataset is needed. `dataset`, through the `defined()` class, allows specifying units of measure, while `datacube` handles the broader needs of attributes, measures, and dimensions.

### From tabular to graph data

The rOpenSci `rdflib` package, a wrapper for the Python library of the same name, provides powerful tools for reading and writing graph data. We believe `dataset` and `rdflib` are complementary and should be used together. While there's a small overlap (inspired by an internal `rdflib` function for working with NQuads, a form of RDF), we've avoided making `rdflib` a direct dependency of `dataset`. However, for users working with RDF-annotated graphs, we strongly recommend using `dataset` in conjunction with `rdflib` for importing, exporting, and exchanging data.

First, let us see how we would solve the ambiguity problems without dataset, relying only on _tidyverse_ and _rdflib_.

```{r two-gdp-datasets}
library(tibble)
library(dplyr)
library(tidyr)

# Dataset D (GDP in billions of USD)
D <- tibble(
  year = c(2020, 2020, 2021, 2021, 2022, 2022),
  geocode = c("USA", "CAN", "USA", "CAN", "USA", "CAN"),
  country_name = c(
    "United States", "Canada", "United States",
    "Canada", "United States", "Canada"
  ),
  GDP = c(21000, 2000, 22000, 2100, 23000, 2200) # GDP in billions of USD
)

# Dataset E (GDP in billions of EUR)
E <- tibble(
  year = c(2020, 2020, 2021, 2021, 2022, 2022),
  geocode = c("USA", "FRA", "USA", "FRA", "USA", "FRA"),
  country_name = c(
    "United States", "France", "United States",
    "France", "United States", "France"
  ),
  GDP = c(18000, 2500, 19000, 2600, 20000, 2700) # GDP in billions of EUR
)

# Combine datasets
combined <- bind_rows(D, E)

# Convert all to character *before* pivoting
combined_char <- combined %>%
  mutate(across(everything(), as.character))

# Rename geocode to subject
combined_subject <- combined_char %>%
  rename(subject = geocode)

# Pivot longer, excluding the subject (triples are named, but predicates are not renamed yet)
named_triples <- combined_subject %>%
  pivot_longer(
    cols = c(year, country_name, GDP), # geocode is excluded
    names_to = "predicate",
    values_to = "object"
  )


# Replace geocodes with Geonames IDs and add datatype annotations
# Try for example <https://www.geonames.org/6251999/>
geonames_mapping <- tibble(
  subject = c("USA", "CAN", "FRA"),
  geonames_id = c("6252001", "6251999", "2988317") # Geonames IDs
)

rdf_triples <- named_triples %>%
  left_join(geonames_mapping, by = "subject") %>%
  mutate(
    subject = paste0("geonames:", geonames_id),
    predicate = case_when(
      predicate == "year" ~ "sdmx:TIME_PERIOD",
      predicate == "country_name" ~ "schema:name",
      predicate == "GDP" ~ "sdmx:OBS_VALUE",
      TRUE ~ predicate
    ),
    object = case_when(
      predicate == "sdmx:TIME_PERIOD" ~ paste0(
        "\"", object, "\"^^<http://www.w3.org/2001/XMLSchema#gYear>"
      ), # Year with datatype
      predicate == "sdmx:OBS_VALUE" ~ paste0(
        "\"", object, "\"^^<http://www.w3.org/2001/XMLSchema#double>"
      ), # GDP with datatype
      TRUE ~ object # Other values as plain strings
    )
  ) %>%
  select(subject, predicate, object)

print("RDF Triples (subject, predicate, object):")
print(rdf_triples)
```

The `frictionless` package has a somewhat similar approach, but it does not support either a metadata standard or a strict serialisation standard.

```{r frictionless, eval=FALSE}
library(tibble)
library(frictionless)

# Dataset D (GDP in millions of USD)
D <- tibble(
  year = c(2020, 2020, 2021, 2021, 2022, 2022),
  geocode = c("USA", "CAN", "USA", "CAN", "USA", "CAN"),
  country_name = c(
    "United States", "Canada", "United States",
    "Canada", "United States", "Canada"
  ),
  GDP = c(
    21000000, 2000000, 22000000,
    2100000, 23000000, 2200000
  ) # GDP in millions of USD
)

# 1. Create a Table resource
table <- Table(D)

# 2. Add metadata (optional but highly recommended)
table$title <- "North American GDP Dataset"
table$description <- "Dataset containing GDP data for North American countries."
table$creator <- "Daniel Antal"
table$publisher <- "Reprex"
table$created <- Sys.Date()

table$language <- "en"
table$schema <- schema(
  fields = list(
    field(
      name = "year",
      type = "integer",
      description = "Year of the observation"
    ),
    field(
      name = "geocode",
      type = "string",
      description = "ISO 3166-1 alpha-3 country code"
    ),
    field(
      name = "country_name",
      type = "string",
      description = "Name of the country"
    ),
    field(
      name = "GDP",
      type = "number",
      description = "Gross Domestic Product (millions of USD)"
    )
  )
)

# 3. Save to CSV (or other formats)
write_table(table, "data/north_america_gdp.csv") # Save as CSV
# write_table(table, "data/north_america_gdp.json") # Save as JSON
# write_table(table, "data/north_america_gdp.xlsx") # Save as Excel

# 4. Create a Data Package (optional, but good practice for bundling resources)
package <- datapackage(
  resources = list(table),
  title = "North American GDP Data",
  description = "Data package containing GDP data for North American countries."
)

# 5. Save the Data Package (creates a datapackage.json and the data files)
write_package(package, "data_package") # Saves to a directory named "data_package"

# You can also validate the datapackage:
# validate_package("data_package")

# And publish it online:
# publish_package("data_package", url = "your_data_repository")  # Replace with your URL
```

The `rdflib` package utilises the World Wide Web RDF standard, which is also used by SDMX and many open science repositories. It allows five different, standard serialisation forms that retain the data and the metadata, including JSON-LD, which is a standard. The `frictionless` solution relies on the JSON quasi-standard for technical interoperability, but it is less strictly defined.

Both packages can carry with a high level of technical interoperability the data and the metadata, however, they leave the user without help on what type of metadata to use. They provide the vehicle, but not really the fuel.

The `dataset` package, and particularly it downstream extensions, the planned `datacube` and the `wbdataset` aims to help the user with metadata curated for a high-level of organisational and semantic interoperability. The `datacube` extension is aiming for compatibility with SDMX and statistical resources like national statistical offices, international organisations, and the EU Open Data Portal; with `wbdataset` we offer sensible defaults to use the Wikibase Data Model.

The downside of both `rdflib` and `frictionless` is that they are agnostic to the conceptual model or data model used by the R user, and most R users do not have the skills to fill in the gaps. A good conceptual model can prevent the user from joining dollar and euro values, but `frictionless` can only attach such information as a string to its containers. The `rdflib` allows a true connection to a formal metadata model, but at the cost of the user need to learn RDF or at least OWL besides R.

In the following example we demonstrate how `dataset` adds semantic richness to the earlier datasets without utilising another language or any external containers.

```{r}
# Dataset D (GDP in millions of USD) with a tibble:
D <- tibble(
  year = c(2020, 2020, 2021, 2021, 2022, 2022),
  geocode = c("USA", "CAN", "USA", "CAN", "USA", "CAN"),
  country_name = c(
    "United States", "Canada", "United States",
    "Canada", "United States", "Canada"
  ),
  GDP = c(
    21000000, 2000000, 22000000,
    2100000, 23000000, 2200000
  ) # GDP in millions of USD
)

# Now let us create a semantically more strict version
geonames_ids <- c("6252001", "6251999")

# Expand geonames_ids
geonames_ids_expanded <- rep(geonames_ids, each = 3)

library(dataset)
# Create the defined_df
D_defined <- dataset_df(
  geonames = defined(geonames_ids_expanded,
    namespace = "http://www.geonames.org/",
    label = "Geonames ID of the country"
  ),
  country_name = D$country_name, # Character vector
  GDP = defined(D$GDP, unit = "M_USD", label = "GDP"),
  dataset_bibentry = dataset::dublincore(
    title = "North American GDP Dataset",
    description = "Dataset containing GDP data for North American countries.",
    creator = person("Daniel", "Antal"), # Replace with the actual creator
    publisher = "Reprex",
    dataset_date = Sys.Date(),
    subject = "GDP"
  )
)

D_defined
```

```{r}
# Create E_defined
geonames_ids_E <- rep(
  c(
    geonames_ids[1],
    geonames_ids[3]
  ),
  each = 3
) # USA and France
E_defined <- dataset_df(
  geonames = defined(geonames_ids_E,
    namespace = "http://www.geonames.org/",
    label = "Geonames ID of the country"
  ),
  country_name = E$country_name,
  GDP = defined(E$GDP, unit = "M_EUR", label = "GDP"),
  dataset_bibentry = dataset::dublincore(
    title = "Euro-based GDP Dataset", # Modified title
    description = "Dataset containing GDP data in euros.", # Modified description
    creator = person(given = "Daniel", family = "Antal"),
    publisher = "Reprex",
    dataset_date = Sys.Date(),
    subject = "GDP"
  )
)
```

So, by now it is clear that the following join must be prohibited.

```{r impossible-join, eval=FALSE}
D_defined %>%
  full_join(E_defined)
```

While the `geonames` and the `country_name` can be joined (the geonames using the same strict definition), the

## Publishing the data

Let us go back to the ISO/IEC 20546 definition used as a motto: "A dataset is an identifiable collection of data available for access or download in one or more formats."

Datasets should be published with the purpose of their potential use and reuse in mind. The `rdflib`, `frictionless` or `dataspice` packages offer different dataset publication vehicles and formats, because they have different reuse in mind.

-   The [rdflib](https://CRAN.R-project.org/package=rdflib) package envisions a fully reusable graph scenario utilising the RDF standard.
-   The [datacite](https://CRAN.R-project.org/package=dataspice) package aims to publish the data with a HTML cover page that is optimised to be found by search engines with encoding the dataset's metadata with the Schema.org's lightweight ontology.
-   The [frictionless](https://CRAN.R-project.org/package=frictionless) package envisions a container that holds metadata in the JSON format and the data in CSV format. This [data package](https://specs.frictionlessdata.io/data-package/#language) is recommended within some open data repositories.
-   The [wbdataset](https://wbdataset.dataobservatory.eu/) package, which is not yet available from CRAN, is aiming to release data with the popular Wikibase graph database format.

The `dataset` package aims compatibility with `rdflib` (for sending datacubes or graph data to APIs); `dataspice` for individually placing datasets to a researcher website, and `wbdataset` for sending the data into Wikibase. It would be also rather easy to create a binding towards `frictionless` if there is user need.

Wikibase, while capable of RDF export and sharing structural similarities with RDF triplestores, is a distinct system bridging relational and graph database elements. Its appeal lies in allowing users to work with graph data without needing to learn RDF and SPARQL, making `rdflib` less practical for direct Wikibase interaction. At the time of `wbdataset`'s development, the `WikibaseR` package was no longer supported. Going forward, `wbdataset` and `WikibaseR` will be co-developed and maintained by the same team, ensuring seamless interaction with Wikibase.

The following example contains individual musical recordings and observed musicological values of such recordings, a general property of the dataset that can be applied to the entire dataset. Similarly, important provenance information, authorship, use rights, and so on, apply to the dataset, not to its specific cells.

```{r smallmusiciandataset1}
small_country_musicians <- data.frame(
  qid = c("Q275912", "Q116196078"),
  artist_name = defined(
    c("Marta Roure", "wavvyboi"),
    definition = "https://www.wikidata.org/wiki/Property:P2093"
  ),
  location = defined(
    c("Andorra", "Lichtenstein"),
    definition = "https://www.wikidata.org/wiki/Property:P276"
  ),
  date_of_birth = defined(
    c(as.Date("1981-01-16"), as.Date("1998-04-28")),
    definition = "https://www.wikidata.org/wiki/Property:P569"
  )
)

small_country_musicians$age <- defined(
  2024 - as.integer(
    substr(
      as.character(small_country_musicians$date_of_birth),
      1, 4
    )
  ),
  label = "Age in 2024"
)
```
